{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/catherine_gai/opt/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as lm \n",
    "import sklearn.preprocessing as preprocess\n",
    "import sklearn.neural_network as nn\n",
    "import sklearn.ensemble as ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = pathlib.Path(\"E0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = [\"E0_13.csv\", \"E0_14.csv\", \"E0_15.csv\", \"E0_16.csv\", \"E0_17.csv\", \"E0_18.csv\"]\n",
    "val_files = [\"E0_19.csv\", \"E0_20.csv\", \"E0_21.csv\"]\n",
    "test_files =[\"E0_22.csv\", \"E0_23.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfs = [pd.read_csv(data_folder / f) for f in train_files] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dfs = [pd.read_csv(data_folder / f) for f in val_files] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dfs = [pd.read_csv(data_folder / f) for f in test_files] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(380, 74), (380, 68), (381, 68), (380, 65), (380, 65), (380, 65)]\n",
      "[(380, 62), (380, 106), (380, 106)]\n",
      "[(380, 106), (380, 106)]\n"
     ]
    }
   ],
   "source": [
    "print([df.shape for df in train_dfs])\n",
    "print([df.shape for df in val_dfs])\n",
    "print([df.shape for df in test_dfs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2281, 65)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.concat(train_dfs, join=\"inner\")\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1140, 44)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.concat(val_dfs, join=\"inner\")\n",
    "val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(760, 106)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.concat(test_dfs, join=\"inner\")\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHS = Home Team Shots\\nAS = Away Team Shots\\nHST = Home Team Shots on Target\\nAST = Away Team Shots on Target\\nHHW = Home Team Hit Woodwork\\nAHW = Away Team Hit Woodwork\\nHC = Home Team Corners\\nAC = Away Team Corners\\nHF = Home Team Fouls Committed\\nAF = Away Team Fouls Committed\\nHFKC = Home Team Free Kicks Conceded\\nAFKC = Away Team Free Kicks Conceded\\nHO = Home Team Offsides\\nAO = Away Team Offsides\\nHY = Home Team Yellow Cards\\nAY = Away Team Yellow Cards\\nHR = Home Team Red Cards\\nAR = Away Team Red Cards\\nHBP = Home Team Bookings Points (10 = yellow, 25 = red)\\nABP = Away Team Bookings Points (10 = yellow, 25 = red)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "HS = Home Team Shots\n",
    "AS = Away Team Shots\n",
    "HST = Home Team Shots on Target\n",
    "AST = Away Team Shots on Target\n",
    "HHW = Home Team Hit Woodwork\n",
    "AHW = Away Team Hit Woodwork\n",
    "HC = Home Team Corners\n",
    "AC = Away Team Corners\n",
    "HF = Home Team Fouls Committed\n",
    "AF = Away Team Fouls Committed\n",
    "HFKC = Home Team Free Kicks Conceded\n",
    "AFKC = Away Team Free Kicks Conceded\n",
    "HO = Home Team Offsides\n",
    "AO = Away Team Offsides\n",
    "HY = Home Team Yellow Cards\n",
    "AY = Away Team Yellow Cards\n",
    "HR = Home Team Red Cards\n",
    "AR = Away Team Red Cards\n",
    "HBP = Home Team Bookings Points (10 = yellow, 25 = red)\n",
    "ABP = Away Team Bookings Points (10 = yellow, 25 = red)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_cols = [\"HomeTeam\", \"AwayTeam\"]\n",
    "x_cols = [\"HS\" ,\"AS\", \"HST\", \"AST\", \"HC\", \"AC\", \"HF\", \"AF\", \"HY\", \"AY\", \"HR\", \"AR\"]\n",
    "y_col = [\"FTR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[team_cols + x_cols + y_col].dropna()\n",
    "val_df = val_df[team_cols + x_cols + y_col].dropna()\n",
    "test_df = test_df[team_cols + x_cols + y_col].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_draw(df): \n",
    "    return df[(df[\"FTR\"] != \"D\") & (df[\"FTR\"] != 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap(x): \n",
    "    if x == \"D\": \n",
    "        return 2 \n",
    "    elif x == \"H\": \n",
    "        return 0 \n",
    "    elif x == \"A\": \n",
    "        return 1 \n",
    "    else: \n",
    "        raise ValuError "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(drop_draw(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[x_cols]\n",
    "Y_train = train_df[y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized = preprocess.normalize(X_train, axis=0)\n",
    "Y_train = Y_train[\"FTR\"].apply(remap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='ovr', random_state=115)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = lm.LogisticRegression(random_state=115, multi_class=\"ovr\")\n",
    "lr_model.fit(X_train_normalized, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4605263157894737"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.score(X_train_normalized, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=[32, 64, 128, 64, 32],\n",
       "              learning_rate_init=0.003, max_iter=5000, random_state=115)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = nn.MLPClassifier(random_state=115, hidden_layer_sizes=[32, 64, 128, 64, 32], max_iter=5000, learning_rate_init=0.003)\n",
    "mlp.fit(X_train_normalized, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5828947368421052"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_train_normalized, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost = ensemble.AdaBoostClassifier()\n",
    "adaboost.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5894736842105263"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = val_df[x_cols]\n",
    "Y_val = val_df[y_col]\n",
    "X_val_normalized = preprocess.normalize(X_val, axis=0)\n",
    "Y_val = Y_val[\"FTR\"].apply(remap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6131578947368421"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_val_normalized, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of Prediction using Historical Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols_home = [c for c in x_cols if c.startswith(\"H\")]\n",
    "x_cols_away = [c for c in x_cols if c.startswith(\"A\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_record(history_df, team): \n",
    "    filtered_history = np.concatenate([history_df[history_df[\"HomeTeam\"] == team][x_cols_home].to_numpy(), \n",
    "                                  history_df[history_df[\"AwayTeam\"] == team][x_cols_away].to_numpy()])\n",
    "    return filtered_history.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for i in range(len(val_df)): \n",
    "    record = {}\n",
    "    record.update(dict(zip(x_cols_home, get_record(train_df, val_df[\"HomeTeam\"].to_numpy()[i]))))\n",
    "    record.update(dict(zip(x_cols_away, get_record(train_df, val_df[\"AwayTeam\"].to_numpy()[i]))))\n",
    "    record.update({\"HomeTeam\": val_df[\"HomeTeam\"].to_numpy()[i], \"AwayTeam\": val_df[\"AwayTeam\"].to_numpy()[i]})\n",
    "    record.update({\"FTR\": val_df[\"FTR\"].to_numpy()[i]})\n",
    "    records.append(record)\n",
    "val_df_new = pd.DataFrame(records, columns=team_cols + x_cols + y_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df_new = val_df_new.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = val_df_new[x_cols]\n",
    "Y_val = val_df_new[y_col]\n",
    "X_val_normalized = preprocess.normalize(X_val, axis=0)\n",
    "Y_val = Y_val[\"FTR\"].apply(remap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5184782608695652"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_val_normalized, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "train_val_df = pd.concat([train_df, val_df])\n",
    "print(len(train_val_df.columns))\n",
    "records = []\n",
    "for i in range(len(val_df)): \n",
    "    record = {}\n",
    "    record.update(dict(zip(x_cols_home, get_record(train_val_df, val_df[\"HomeTeam\"].to_numpy()[i]))))\n",
    "    record.update(dict(zip(x_cols_away, get_record(train_val_df, val_df[\"AwayTeam\"].to_numpy()[i]))))\n",
    "    record.update({\"HomeTeam\": val_df[\"HomeTeam\"].to_numpy()[i], \"AwayTeam\": val_df[\"AwayTeam\"].to_numpy()[i]})\n",
    "    record.update({\"FTR\": val_df[\"FTR\"].to_numpy()[i]})\n",
    "    records.append(record)\n",
    "test_df_new = pd.DataFrame(records, columns=team_cols + x_cols + y_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df_new[x_cols]\n",
    "Y_test = test_df_new[y_col]\n",
    "X_test_normalized = preprocess.normalize(X_test, axis=0)\n",
    "Y_test = Y_test[\"FTR\"].apply(remap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5201754385964912"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_test_normalized, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
